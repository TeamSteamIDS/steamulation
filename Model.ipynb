{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_num_games(g_id, u_id):\n",
    "    target = \"\"\n",
    "    for g in classification:\n",
    "        if g_id in classification[g]:\n",
    "            target = g\n",
    "            break\n",
    "    return user[u_id][target]\n",
    "\n",
    "def get_avg_user_level(g_id):\n",
    "    level_total = 0\n",
    "    cnt = 0\n",
    "    for u in game_user[g_id]:\n",
    "        if u in user:\n",
    "            level_total = level_total + user[u]['userLevel']\n",
    "            cnt = cnt + 1\n",
    "    return level_total/cnt\n",
    "\n",
    "def get_avg_user_playtime(g_id):\n",
    "    playtime_total = 0\n",
    "    cnt = 0\n",
    "    for u in game_user[g_id]:\n",
    "        playtime_total = playtime_total + game_user[g_id][u]['total_play_time']\n",
    "        cnt = cnt + 1\n",
    "    return playtime_total/cnt\n",
    "\n",
    "def get_avg_user_playtime_in_G(g_id):\n",
    "    playtime_total = 0\n",
    "    num_user = 0\n",
    "    target = \"\"\n",
    "    for g in classification:\n",
    "        if g_id in classification[g]:\n",
    "            target = g\n",
    "            break\n",
    "    for all_other_g in classification[target]:\n",
    "        if all_other_g not in result:\n",
    "            continue\n",
    "        for u in game_user[all_other_g]:\n",
    "            playtime_total = playtime_total + game_user[all_other_g][u]['total_play_time']\n",
    "            num_user = num_user + len(game_user[all_other_g])\n",
    "    return playtime_total/num_user\n",
    "\n",
    "def get_user_playtime(g_id, u_id):\n",
    "    return game_user[g_id][u_id]['total_play_time']\n",
    "\n",
    "def get_user_level(u_id):\n",
    "    return user[u_id]['userLevel']\n",
    "\n",
    "#remember to load pickle file: review.p\n",
    "def get_total_review_g(g_id):\n",
    "    count = 0\n",
    "    for each in review:\n",
    "        if review[each]['game_id'] == g_id:\n",
    "            count = count + 1\n",
    "    #print('{0} : {1} '.format(g_id,count))\n",
    "    return count\n",
    "\n",
    "\n",
    "def get_total_review_u(u_id):\n",
    "    count = 0\n",
    "    for each in review:\n",
    "        if review[each]['user_id'] == u_id:\n",
    "            count = count + 1\n",
    "    #print('{0} : {1} '.format(u_id,count))\n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 28413\n",
      "1000 28413\n",
      "2000 28413\n",
      "3000 28413\n",
      "4000 28413\n",
      "5000 28413\n",
      "6000 28413\n",
      "7000 28413\n",
      "8000 28413\n",
      "9000 28413\n",
      "10000 28413\n",
      "11000 28413\n",
      "12000 28413\n",
      "13000 28413\n",
      "14000 28413\n",
      "15000 28413\n",
      "16000 28413\n",
      "17000 28413\n",
      "18000 28413\n",
      "19000 28413\n",
      "20000 28413\n",
      "21000 28413\n",
      "22000 28413\n",
      "23000 28413\n",
      "24000 28413\n",
      "25000 28413\n",
      "26000 28413\n",
      "27000 28413\n",
      "28000 28413\n",
      "28413\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "with open(\"dicts/result.p\", \"rb\") as f:\n",
    "    result = pickle.load(f)\n",
    "with open(\"dicts/classification.p\", \"rb\") as f:\n",
    "    classification = pickle.load(f)\n",
    "with open(\"dicts/userDictionary_all.p\", \"rb\") as f:\n",
    "    user = pickle.load(f)\n",
    "with open(\"dicts/game_user.p\", \"rb\") as f:\n",
    "    game_user = pickle.load(f)\n",
    "with open(\"dicts/review.p\", \"rb\") as f:\n",
    "    review = pickle.load(f)\n",
    "\n",
    "            \n",
    "cnt = 0\n",
    "#print(result['4290'])\n",
    "for key in result:\n",
    "    if key not in game_user:\n",
    "        result.pop(key)\n",
    "\n",
    "for i in result:\n",
    "    cnt = cnt + len(result[i])\n",
    "#print(result)\n",
    "test_size = cnt * 0.2\n",
    "test = {}\n",
    "train = {}\n",
    "while len(test) < test_size:\n",
    "    g_id, val = random.choice(list(result.items()))\n",
    "    u_id, res = random.choice(list(val.items()))\n",
    "    tup = (g_id, u_id)\n",
    "    if tup not in test:\n",
    "        test[tup] = res\n",
    "#print(test)\n",
    "for g_id in result:\n",
    "    for u_id in result[g_id]:\n",
    "        tup = (g_id, u_id)\n",
    "        #print(tup)\n",
    "        if tup not in test:\n",
    "            #print(result[g_id][u_id])\n",
    "            train[tup] = result[g_id][u_id]\n",
    "            \n",
    "#print(list(game_user.keys()))\n",
    "len_train = len(train)\n",
    "N = len_train\n",
    "X_train = np.zeros((N+1, 8))\n",
    "Y_train = np.zeros((N+1, 1))\n",
    "cnt = 0\n",
    "for key in train:\n",
    "    #print(key, train[key])\n",
    "    g_id = key[0]\n",
    "    u_id = key[1]\n",
    "    #l = []\n",
    "    X_train[cnt,0] = get_num_games(g_id, u_id)\n",
    "    X_train[cnt,1] = get_avg_user_level(g_id)\n",
    "    X_train[cnt,2] = get_avg_user_playtime(g_id)\n",
    "    X_train[cnt,3] = get_avg_user_playtime_in_G(g_id)\n",
    "    X_train[cnt,4] = get_user_playtime(g_id, u_id)\n",
    "    X_train[cnt,5] = get_user_level(u_id)\n",
    "    X_train[cnt,6] = get_total_review_g(g_id)\n",
    "    X_train[cnt,7] = get_total_review_u(u_id)\n",
    "    Y_train[cnt] = result[g_id][u_id]\n",
    "    if cnt % 1000 == 0:\n",
    "        print(cnt, len_train)\n",
    "    cnt = cnt + 1\n",
    "    if cnt > N:\n",
    "        break\n",
    "print(cnt)\n",
    "print('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 28413\n",
      "100 28413\n",
      "200 28413\n",
      "300 28413\n",
      "400 28413\n",
      "500 28413\n",
      "600 28413\n",
      "700 28413\n",
      "800 28413\n",
      "900 28413\n",
      "1000 28413\n",
      "1100 28413\n",
      "1200 28413\n",
      "1300 28413\n",
      "1400 28413\n",
      "1500 28413\n",
      "1600 28413\n",
      "1700 28413\n",
      "1800 28413\n",
      "1900 28413\n",
      "2000 28413\n",
      "2100 28413\n",
      "2200 28413\n",
      "2300 28413\n",
      "2400 28413\n",
      "2500 28413\n",
      "2600 28413\n",
      "2700 28413\n",
      "2800 28413\n",
      "2900 28413\n",
      "3000 28413\n",
      "3100 28413\n",
      "3200 28413\n",
      "3300 28413\n",
      "3400 28413\n",
      "3500 28413\n",
      "3600 28413\n",
      "3700 28413\n",
      "3800 28413\n",
      "3900 28413\n",
      "4000 28413\n",
      "4100 28413\n",
      "4200 28413\n",
      "4300 28413\n",
      "4400 28413\n",
      "4500 28413\n",
      "4600 28413\n",
      "4700 28413\n",
      "4800 28413\n",
      "4900 28413\n",
      "5000 28413\n",
      "5100 28413\n",
      "5200 28413\n",
      "5300 28413\n",
      "5400 28413\n",
      "5500 28413\n",
      "5600 28413\n",
      "5683\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "#len_train = len(train)\n",
    "X_test = np.zeros((round(N/5)+1, 8))\n",
    "Y_test = np.zeros((round(N/5)+1, 1))\n",
    "cnt = 0\n",
    "for key in test:\n",
    "    #print(key, train[key])\n",
    "    g_id = key[0]\n",
    "    u_id = key[1]\n",
    "    #l = []\n",
    "    if u_id not in user:\n",
    "        continue\n",
    "    X_test[cnt,0] = get_num_games(g_id, u_id)\n",
    "    X_test[cnt,1] = get_avg_user_level(g_id)\n",
    "    X_test[cnt,2] = get_avg_user_playtime(g_id)\n",
    "    X_test[cnt,3] = get_avg_user_playtime_in_G(g_id)\n",
    "    X_test[cnt,4] = get_user_playtime(g_id, u_id)\n",
    "    X_test[cnt,5] = get_user_level(u_id)\n",
    "    X_test[cnt,6] = get_total_review_g(g_id)\n",
    "    X_test[cnt,7] = get_total_review_u(u_id)\n",
    "    Y_test[cnt] = int(result[g_id][u_id])\n",
    "    if cnt % 100 == 0:\n",
    "        print(cnt, len_train)\n",
    "    cnt = cnt + 1\n",
    "    if cnt > N/5:\n",
    "        break\n",
    "print(cnt)\n",
    "print('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nmodel_S = SVC(kernel=\"linear\", probability = True)\\nmodel_R = SVC(kernel=\"rbf\", probability = True)\\n\\nmodel_S.fit(X_train, np.ravel(Y_train))\\nmodel_R.fit(X_train,np.ravel(Y_train))\\nprint(model_S.score(X_test, np.ravel(Y_test)))\\nprint(model_R.score(X_test, np.ravel(Y_test)))\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#N = 4000\n",
    "#X_small = X_train[1:N,:]\n",
    "#Y_small = Y_train[1:N,:]\n",
    "#X_st = X_test[1:N/5,:]\n",
    "#Y_st = Y_test[1:N/5,:]\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "%matplotlib inline\n",
    "from sklearn.svm import SVC\n",
    "'''\n",
    "\n",
    "model_S = SVC(kernel=\"linear\", probability = True)\n",
    "model_R = SVC(kernel=\"rbf\", probability = True)\n",
    "\n",
    "model_S.fit(X_train, np.ravel(Y_train))\n",
    "model_R.fit(X_train,np.ravel(Y_train))\n",
    "print(model_S.score(X_test, np.ravel(Y_test)))\n",
    "print(model_R.score(X_test, np.ravel(Y_test)))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.metrics import fbeta_score, make_scorer, average_precision_score, classification_report\n",
    "\n",
    "parameter_candidates = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "# Create a classifier object with the classifier and parameter candidates\n",
    "clf = GridSearchCV(estimator=SVC(), param_grid=parameter_candidates)\n",
    "clf.fit(X_train, np.ravel(Y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Best score for data1:', clf.best_score_)\n",
    "print('Best C:',clf.best_estimator_.C)\n",
    "print('Best Kernel:',clf.best_estimator_.kernel)\n",
    "print('Best Gamma:',clf.best_estimator_.gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.score(X_test,np.ravel(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SVC(C=100, kernel='linear', gamma='auto').fit(X_train, np.ravel(Y_train)).score(X_test, np.ravel(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
